<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html" charset="UTF-8">

<title>TrackMaze: A Comparison of Head-tracking, Eye-tracking, and Tilt as Input 
Methods for Mobile Games
</title>

</head>

<body>
<blockquote>
<hr>
<font size="-1">
Abbaszadegan, M., Yaghoubi, S., & MacKenzie, I. S. (2018).
TrackMaze: A comparison of head-tracking, eye-tracking, and tilt as input methods for mobile games.
Proceedings of 20th International Conference on Human-Computer Interaction - HCII 2018
(LNCS 10903) pp. 393-405.
Berlin: Springer.
doi:10.1007/978-3-319-91250-9_31
[<a href="hcii2018b.pdf">PDF</a>]
[<a href="https://youtu.be/5jyJHRM6X0I">video</a>]
</font>
<hr>
<p>

<blockquote>
<center>
<h1>
TrackMaze: A Comparison of Head-tracking, Eye-tracking, and Tilt as Input Methods 
for Mobile Games

<h3>
Mahdieh Abbaszadegan, Sohrab Yaghoubi, & <a href="http://www.yorku.ca/mack/">I.  
Scott MacKenzie</a>
</h3>

York University<br>
Dept of Electrical Engineering and Computer Science<br>
Toronto,  Canada<br>
mahdieh@eecs.yorku.ca,
sohrab.y93@gmail.com,
mack@cse.yorku.ca
<p>
</center>

<B>Abstract</B>
A user study was performed to compare three input methods (tilt, eye-tracking, head-tracking) with two gain levels (low, high) on a custom-made <I>TrackMaze</I> mobile game. The task involved maneuvering a virtual ball through a maze while trying to avoid walls. The game was developed in Swift using the ARKit framework. The TrueDepth front-facing camera of an Apple <I>iPhone X</I> was used for the eye-tracking and head-tracking conditions. We evaluated user performance (maze completion time, number of wall hits) and qualitative measures (ease of use, enjoyment, fatigue). Tilt input showed the best performance and eye-tracking showed the worst performance. The mean maze completion time was 12.3 seconds for tilt, 22.5 seconds for head-tracking, and 31.8 seconds for eye-tracking. High gain was 26% faster than low gain. Tilt was the most precise input method with only 1.06 wall hits per trial, compared to head-tracking (2.30) and eye-tracking (4.00). Participants preferred tilt and head-tracking over eye-tracking and noted that the eye-tracking interface was fatiguing and hard to use.
<p>

<B>Keywords:</B> HCI, Mobile Games, Augmented Reality on Mobile Devices, ARKit, 
iOS, Head-tracking, Eye-tracking, Tilt-input
<p>

</blockquote>

<H2>1 Introduction
</H2>
<p>

Many computer users are switching from personal computers to smartphones or 
tablets for their daily computing needs. This transition has created growth in 
mobile application development, with many companies offering exclusive services 
and promotions over their mobile apps.  The goal is to lure users to smartphones. 
And the rewards are huge.  Since launching the App Store in 2008, Apple's 
developer community has earned $70 billion worldwide, with $20 billion in 2016 
alone [12, 13].  Furthermore, gaming is the top-grossing across 25 app categories, 
with games accounting for 25% of all available apps [20].  This paper focuses on 
input methods for mobile games.
<p>

  Smartphones receive input through a touchscreen, a camera, microphone, 
  accelerometer, etc. Touch input is the primary input method on smartphones, and 
  this is also true for mobile games. Some drawbacks of touch input for the player 
  are lack of tactile feedback and occlusion of the display [8]. Smartphones and 
  tablets typically include an accelerometer which measures the tilting motion and 
  the physical orientation of the device. Device orientation can be used for 
  controlling game objects. Such control, commonly called "tilt", is widely used 
  as an input method in mobile games. In addition, a smartphone's camera can track 
  movement in the real world. Using the front-facing camera, we can track the 
  user's face or eye, and even obtain their facial expression. Thus, eye-tracking 
  and head-tracking are possible input methods for hands-free games, in addition 
  to tilt.  One benefit of hands-free input is to provide more entertainment 
  options for people with special needs. However, using the eyes as an input 
  method is problematic, since the eyes are also our main perception method [16]. 
  Notably, ease of use and novelty has an impact on "perceived enjoyment" in 
  mobile games [18]. 
<p>

  With iOS 11, Apple introduced ARKit, a framework for creating Augmented Reality 
  (AR) apps for the <I>iPhone</I> and <I>iPad</I>. ARKit combined with the TrueDepth 
  front-facing camera available on the <I>iPhone X</I> enables face or eye tracking in AR 
  apps. The TrueDepth camera gives the position, orientation, and expression of 
  the face in real-time. It also enables Face ID, the facial recognition method 
  for authentication on an <I>iPhone X</I>. 
<p>

  In this paper, we evaluate the functionality of eye-tracking and head-tracking, 
  using ARKit and the TrueDepth camera. We compare tilt-input, head-tracking, and 
  eye-tracking for a custom-designed game called <I>TrackMaze</I>. With <I>TrackMaze</I>, the 
  player navigates a virtual ball through a static maze. We address several 
  questions: Is it possible to use eye-tracking and head-tracking for mobile games 
  that need whole-display navigation? Can eye-tracking and head-tracking result in 
  better perceived enjoyment? Can eye-tracking or head-tracking compete with 
  tilt-input, the natural input method for maze games? Which input method is 
  easiest to use? Do users prefer one input method over the others?
<p>

  In the next section, we review studies on mobile games related to tilt-input, 
  eye-tracking, and head tracking. Then, we discuss the methodology and results of 
  our user study. We then offer conclusions on user performance and enjoyment for 
  tilt, eye-tracking, and head-tracking as input methods.<p>

<H2>
Related Work
</H2>

<p>
</blockquote>
</body>
</html>